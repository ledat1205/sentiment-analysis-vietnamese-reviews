{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wjtcTaQ6Krbj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import unicodedata\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "crpvJAYYMUlS"
   },
   "outputs": [],
   "source": [
    "with open('data/stopword.txt', 'r' , encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "    stopwords = [i for i in stopwords if i.find(\" \")==-1]\n",
    "bang_nguyen_am= [['a', '√†', '√°', '·∫£', '√£', '·∫°', 'a'],\n",
    "                  ['ƒÉ', '·∫±', '·∫Ø', '·∫≥', '·∫µ', '·∫∑', 'aw'],\n",
    "                  ['√¢', '·∫ß', '·∫•', '·∫©', '·∫´', '·∫≠', 'aa'],\n",
    "                  ['e', '√®', '√©', '·∫ª', '·∫Ω', '·∫π', 'e'],\n",
    "                  ['√™', '·ªÅ', '·∫ø', '·ªÉ', '·ªÖ', '·ªá', 'ee'],\n",
    "                  ['i', '√¨', '√≠', '·ªâ', 'ƒ©', '·ªã', 'i'],\n",
    "                  ['o', '√≤', '√≥', '·ªè', '√µ', '·ªç', 'o'],\n",
    "                  ['√¥', '·ªì', '·ªë', '·ªï', '·ªó', '·ªô', 'oo'],\n",
    "                  ['∆°', '·ªù', '·ªõ', '·ªü', '·ª°', '·ª£', 'ow'],\n",
    "                  ['u', '√π', '√∫', '·ªß', '≈©', '·ª•', 'u'],\n",
    "                  ['∆∞', '·ª´', '·ª©', '·ª≠', '·ªØ', '·ª±', 'uw'],\n",
    "                  ['y', '·ª≥', '√Ω', '·ª∑', '·ªπ', '·ªµ', 'y']]\n",
    "\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "# Chu·∫©n h√≥a unicode \n",
    "# C√≥ 2 lo·∫°i unicode : unicode t·ªï h∆°p v√† unicode d·ª±ng s·∫µn, ƒëi√™u n√†y d·∫´n t·ªõi vi·ªác 2 t·ª´ gi·ªëng nhau s·∫Ω b·ªã coi l√† kh√°c nhau \n",
    "# Chu·∫©n h√≥a t·∫•t c·∫£ v·ªÅ 1 lo·∫°i l√† unicode d·ª±ng s·∫µn\n",
    "def chuan_hoa_unicode(text):\n",
    "\ttext = unicodedata.normalize('NFC', text)\n",
    "\treturn text\n",
    "\n",
    "# C√≥ 2 ki·ªÉu g√µ d·∫•u ·ªü Ti·∫øng Vi·ªát, v√≠ d·ª• nh∆∞ l√† : √≤a ho·∫∑c o√† (ta g·ªçi l·∫ßn l∆∞·ª£t l√† chu·∫©n 1 v√† 2). M·∫∑c d√π ki·ªÉu g√µ ch·ªØ sau √≠t \n",
    "#ph·ªï bi·∫øn h∆°n tuy nhi√™n v·∫´n c·∫ßn ph·∫£i chu·∫©n h√≥a tr√°nh vi·ªác m·ªôt s·ªë vƒÉn b·∫£n v·∫´n s·ª≠ d·ª•ng ki·ªÉu g√µ d·∫•u th·ª© 2.\n",
    "\"\"\"\n",
    "\tH√†m n√†y x·ª≠ l√Ω chu·∫©n h√≥a t·ª´ng t·ª´ m·ªôt, sau khi chu·∫©n h√≥a t·ª´ng t·ª´ th√¨ ta s·∫Ω ƒëi chu√¢n h√≥a t·ª´ng c√¢u sau \n",
    "\t\"\"\" \n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    " \n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    " \n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # √™, ∆°\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    " \n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuy·ªÉn c√¢u ti·∫øng vi·ªát v·ªÅ chu·∫©n g√µ d·∫•u ki·ªÉu c≈©.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        # print(cw)\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# T√°ch t·ª´ ti·∫øng vi·ªát, t·ª´ ti·∫øng vi·ªát kh√¥ng gi·ªëng nh∆∞ ti·∫øng anh, t√°ch t·ª´ ti·∫øng anh ta ch·ªâ c·∫ßn t√°ch b·∫±ng kho·∫£ng tr·∫Øng\n",
    "# Tuy nhi√™n t·ª´ ti·∫øng Vi·ªát c√≥ c·∫£ t·ª´ ƒë∆°n l·∫´n t·ª´ gh√©p n√™n t√°ch t·ª´ ti√™ng Vi·ªát s·∫Ω ph√∫c t·∫°p h∆°n \n",
    "# Project s·ª≠ dung thu vi·ªán pyvi (xem m√£ ngu·ªìn t·∫°i : https://github.com/trungtv/pyvi) ƒë·ªÉ ph·ª•c v·ª• b√†i to√°n con t√°ch t·ª´ Ti·∫øng Vi·ªát \n",
    "# def tach_tu_tieng_viet(text):\n",
    "# \ttext = ViTokenizer.tokenize(text)\n",
    "# \treturn text\n",
    "\n",
    "# ƒê∆∞a v·ªÅ ch·ªØ vi·∫øt th∆∞·ªùng \n",
    "def get_lower(text):\n",
    "        return text.lower().strip()\n",
    "\n",
    "# X√≥a ƒëi c√°c d·∫•u c√°ch th·ª´a, c√°c t·ª´ kh√¥ng c·∫ßn thi·∫øt cho vi·ªác ph√¢n lo·∫°i v·∫≥n b·∫£n \n",
    "def chuan_hoa_cau(text):\n",
    "\ttext = re.sub(r'[^\\s\\w√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë_]',' ',text)\n",
    "\ttext = re.sub(r'\\s+', ' ', text).strip()\n",
    "\treturn text\n",
    "\n",
    "def remove_tag (text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'http\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = string.punctuation\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "\n",
    "def remove_stopW(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = [i for i in new_text if i != '']\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\" \n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_data(text):\n",
    "    text = get_lower(text)\n",
    "    text = remove_tag(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_stopW(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_punc(text)\n",
    "    text = chuan_hoa_unicode(text)\n",
    "    text = chuan_hoa_dau_cau_tieng_viet(text)\n",
    "    # text = tach_tu_tieng_viet(text)\n",
    "    text = chuan_hoa_cau(text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     file = open(\"test.txt\", \"r\", encoding=\"utf-8\")\n",
    "#     data = file.read()\n",
    "#     data = tien_xu_li(data)\n",
    "#     print(\"V√≠ d·ª• : \\n\")\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEd7caaETDUy"
   },
   "outputs": [],
   "source": [
    "text = ['U·ªëng r·∫•t ngon Giao h√†ng nhanh Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi.....................üòãüòãüòãüòã......................',\n",
    "        'L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ƒë·ª£t n√†y l·∫°i giao 2 c√°i √°o gi√≥ ch·∫•t kh√°c nh∆∞ v·∫£i m∆∞a √Ω :((',\n",
    "        'San Pham tuyet voi.. Giay ray Dep..  Cho 5sao luon nha shop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1672431772557,
     "user": {
      "displayName": "Th√†nh ƒê·∫°t L√™",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "ZEMY0mwQq5oS",
    "outputId": "84b3ff38-97fc-4eaa-eca2-fead8ae73216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u·ªëng ngon giao h√†ng nhanh ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi',\n",
       " 'l·∫ßn mua √°o gi√≥ m√†u h·ªìng ok ƒë·ª£t giao 2 √°o gi√≥ ch·∫•t kh√°c v·∫£i m∆∞a √Ω',\n",
       " 'san pham tuyet voi giay ray dep 5sao luon nha shop']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "for i in text:\n",
    "    clean_text.append(clean_data(i))\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1672409998886,
     "user": {
      "displayName": "Th√†nh ƒê·∫°t L√™",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "GHj7ZWq3TFwE",
    "outputId": "51d03d23-7773-49bb-ad4a-deb7c1b2de85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\r\\nshop ƒê√≥ng g√≥i s·∫£n ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞ng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v·ªç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ƒë...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            comment  label\n",
       "0  train_000000  Dung dc sp tot cam on \\r\\nshop ƒê√≥ng g√≥i s·∫£n ph...      0\n",
       "1  train_000001   Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞ng...      0\n",
       "2  train_000002   Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp ...      0\n",
       "3  train_000003  :(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v·ªç...      1\n",
       "4  train_000004  L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ƒë...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13649,
     "status": "ok",
     "timestamp": 1672410012528,
     "user": {
      "displayName": "Th√†nh ƒê·∫°t L√™",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "kETjvjTLW9vG",
    "outputId": "f20eb5ea-9529-4f7c-8d2a-58c50218a899"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>dung dc sp tot cam on shop ƒë√≥ng g√≥i s·∫£n ph·∫©m ƒë...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi son m·ªãn ƒë√°nh m√†u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi k h·ªôp k d√¢y gi√†y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>h∆°i th·∫•t v·ªçng 1 ch√∫t k·ª≥ v·ªçng cu·ªën s√°ch kh√° hi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>l·∫ßn mua √°o gi√≥ m√†u h·ªìng ok ƒë·ª£t giao 2 √°o gi√≥ c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            comment  label\n",
       "0  train_000000  dung dc sp tot cam on shop ƒë√≥ng g√≥i s·∫£n ph·∫©m ƒë...      0\n",
       "1  train_000001  ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi son m·ªãn ƒë√°nh m√†u...      0\n",
       "2  train_000002  ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi k h·ªôp k d√¢y gi√†y...      0\n",
       "3  train_000003  h∆°i th·∫•t v·ªçng 1 ch√∫t k·ª≥ v·ªçng cu·ªën s√°ch kh√° hi ...      1\n",
       "4  train_000004  l·∫ßn mua √°o gi√≥ m√†u h·ªìng ok ƒë·ª£t giao 2 √°o gi√≥ c...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['comment'] = train_data['comment'].apply(lambda x: clean_data(str(x)))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dtXs9ZEuXcQT"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv('data/clean_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
