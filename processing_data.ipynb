{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wjtcTaQ6Krbj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import unicodedata\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "crpvJAYYMUlS"
   },
   "outputs": [],
   "source": [
    "with open('data/stopword.txt', 'r' , encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "    stopwords = [i for i in stopwords if i.find(\" \")==-1]\n",
    "bang_nguyen_am= [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "# Chuẩn hóa unicode \n",
    "# Có 2 loại unicode : unicode tổ hơp và unicode dựng sẵn, điêu này dẫn tới việc 2 từ giống nhau sẽ bị coi là khác nhau \n",
    "# Chuẩn hóa tất cả về 1 loại là unicode dựng sẵn\n",
    "def chuan_hoa_unicode(text):\n",
    "\ttext = unicodedata.normalize('NFC', text)\n",
    "\treturn text\n",
    "\n",
    "# Có 2 kiểu gõ dấu ở Tiếng Việt, ví dụ như là : òa hoặc oà (ta gọi lần lượt là chuẩn 1 và 2). Mặc dù kiểu gõ chữ sau ít \n",
    "#phổ biến hơn tuy nhiên vẫn cần phải chuẩn hóa tránh việc một số văn bản vẫn sử dụng kiểu gõ dấu thứ 2.\n",
    "\"\"\"\n",
    "\tHàm này xử lý chuẩn hóa từng từ một, sau khi chuẩn hóa từng từ thì ta sẽ đi chuân hóa từng câu sau \n",
    "\t\"\"\" \n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    " \n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    " \n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    " \n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        # print(cw)\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Tách từ tiếng việt, từ tiếng việt không giống như tiếng anh, tách từ tiếng anh ta chỉ cần tách bằng khoảng trắng\n",
    "# Tuy nhiên từ tiếng Việt có cả từ đơn lẫn từ ghép nên tách từ tiêng Việt sẽ phúc tạp hơn \n",
    "# Project sử dung thu viện pyvi (xem mã nguồn tại : https://github.com/trungtv/pyvi) để phục vụ bài toán con tách từ Tiếng Việt \n",
    "# def tach_tu_tieng_viet(text):\n",
    "# \ttext = ViTokenizer.tokenize(text)\n",
    "# \treturn text\n",
    "\n",
    "# Đưa về chữ viết thường \n",
    "def get_lower(text):\n",
    "        return text.lower().strip()\n",
    "\n",
    "# Xóa đi các dấu cách thừa, các từ không cần thiết cho việc phân loại vẳn bản \n",
    "def chuan_hoa_cau(text):\n",
    "\ttext = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',text)\n",
    "\ttext = re.sub(r'\\s+', ' ', text).strip()\n",
    "\treturn text\n",
    "\n",
    "def remove_tag (text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'http\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = string.punctuation\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "\n",
    "def remove_stopW(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = [i for i in new_text if i != '']\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\" \n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_data(text):\n",
    "    text = get_lower(text)\n",
    "    text = remove_tag(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_stopW(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_punc(text)\n",
    "    text = chuan_hoa_unicode(text)\n",
    "    text = chuan_hoa_dau_cau_tieng_viet(text)\n",
    "    # text = tach_tu_tieng_viet(text)\n",
    "    text = chuan_hoa_cau(text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     file = open(\"test.txt\", \"r\", encoding=\"utf-8\")\n",
    "#     data = file.read()\n",
    "#     data = tien_xu_li(data)\n",
    "#     print(\"Ví dụ : \\n\")\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEd7caaETDUy"
   },
   "outputs": [],
   "source": [
    "text = ['Uống rất ngon Giao hàng nhanh Chất lượng sản phẩm tuyệt vời.....................😋😋😋😋......................',\n",
    "        'Lần trước mình mua áo gió màu hồng rất ok mà đợt này lại giao 2 cái áo gió chất khác như vải mưa ý :((',\n",
    "        'San Pham tuyet voi.. Giay ray Dep..  Cho 5sao luon nha shop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1672431772557,
     "user": {
      "displayName": "Thành Đạt Lê",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "ZEMY0mwQq5oS",
    "outputId": "84b3ff38-97fc-4eaa-eca2-fead8ae73216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uống ngon giao hàng nhanh chất lượng sản phẩm tuyệt vời',\n",
       " 'lần mua áo gió màu hồng ok đợt giao 2 áo gió chất khác vải mưa ý',\n",
       " 'san pham tuyet voi giay ray dep 5sao luon nha shop']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "for i in text:\n",
    "    clean_text.append(clean_data(i))\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1672409998886,
     "user": {
      "displayName": "Thành Đạt Lê",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "GHj7ZWq3TFwE",
    "outputId": "51d03d23-7773-49bb-ad4a-deb7c1b2de85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on \\r\\nshop Đóng gói sản ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            comment  label\n",
       "0  train_000000  Dung dc sp tot cam on \\r\\nshop Đóng gói sản ph...      0\n",
       "1  train_000001   Chất lượng sản phẩm tuyệt vời . Son mịn nhưng...      0\n",
       "2  train_000002   Chất lượng sản phẩm tuyệt vời nhưng k có hộp ...      0\n",
       "3  train_000003  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...      1\n",
       "4  train_000004  Lần trước mình mua áo gió màu hồng rất ok mà đ...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13649,
     "status": "ok",
     "timestamp": 1672410012528,
     "user": {
      "displayName": "Thành Đạt Lê",
      "userId": "09816430981743690437"
     },
     "user_tz": -420
    },
    "id": "kETjvjTLW9vG",
    "outputId": "f20eb5ea-9529-4f7c-8d2a-58c50218a899"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>dung dc sp tot cam on shop đóng gói sản phẩm đ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>chất lượng sản phẩm tuyệt vời son mịn đánh màu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>chất lượng sản phẩm tuyệt vời k hộp k dây giày...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>hơi thất vọng 1 chút kỳ vọng cuốn sách khá hi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>lần mua áo gió màu hồng ok đợt giao 2 áo gió c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            comment  label\n",
       "0  train_000000  dung dc sp tot cam on shop đóng gói sản phẩm đ...      0\n",
       "1  train_000001  chất lượng sản phẩm tuyệt vời son mịn đánh màu...      0\n",
       "2  train_000002  chất lượng sản phẩm tuyệt vời k hộp k dây giày...      0\n",
       "3  train_000003  hơi thất vọng 1 chút kỳ vọng cuốn sách khá hi ...      1\n",
       "4  train_000004  lần mua áo gió màu hồng ok đợt giao 2 áo gió c...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['comment'] = train_data['comment'].apply(lambda x: clean_data(str(x)))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dtXs9ZEuXcQT"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv('data/clean_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
